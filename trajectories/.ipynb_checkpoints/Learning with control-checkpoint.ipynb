{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import crocoddyl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.... HYPERPARAMS\n",
    "\n",
    "\n",
    "\n",
    "BATCHSIZE     = 64\n",
    "lr            = 1e-3\n",
    "DECAY         = 0.09\n",
    "\n",
    "DEVICE        = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "\n",
    "        def __init__(self, \n",
    "                     input_dims:int  = 3,\n",
    "                     output_dims:int = 90,\n",
    "                     fc1_dims:int    = 256,\n",
    "                     fc2_dims:int    = 256,\n",
    "                     fc3_dims:int    = 2,\n",
    "                     activation      = nn.Tanh(),\n",
    "                     device:str      = 'cpu'\n",
    "                     ):\n",
    "\n",
    "\n",
    "                super(PolicyNetwork, self).__init__()\n",
    "                \"\"\"Instantiate an untrained neural network with the given params\n",
    "\n",
    "                Args\n",
    "                ........\n",
    "                        \n",
    "                        1: input_dims   = dimensions of the state space of the robot. 3 for unicycle\n",
    "                        2: output_dims  = dimensions of the next state\n",
    "                        3: fc1_dims     = number of units in the first fully connected layer. Default 100\n",
    "                        4: fc2_dims     = number of units in the second fully connected layer. Default 100\n",
    "                        5: fc3_dims     = number of units in the third fully connected layer. Default 1\n",
    "                        6: activation   = activation for the layers, default ReLU.\n",
    "                        7: device       = device for computations. Generally CPU\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "                self.input_dims    = input_dims\n",
    "                self.output_dims   = output_dims\n",
    "                self.fc1_dims      = fc1_dims\n",
    "                self.fc2_dims      = fc2_dims\n",
    "                self.fc3_dims      = fc3_dims\n",
    "                self.activation    = activation\n",
    "\n",
    "\n",
    "                #........... Structure\n",
    "                self.fc1 = nn.Linear(self.input_dims, self.fc1_dims)\n",
    "                self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "                self.fc3 = nn.Linear(self.fc2_dims, self.fc3_dims)\n",
    "                self.fc4 = nn.Linear(self.fc3_dims, self.output_dims)\n",
    "\n",
    "                #........... Weight Initialization protocol\n",
    "                nn.init.xavier_uniform_(self.fc1.weight)\n",
    "                nn.init.xavier_uniform_(self.fc2.weight)\n",
    "                nn.init.xavier_uniform_(self.fc3.weight)\n",
    "                nn.init.xavier_uniform_(self.fc4.weight)\n",
    "\n",
    "                \n",
    "                #........... Bias Initialization protocol\n",
    "                nn.init.constant_(self.fc1.bias, 0.003)\n",
    "                nn.init.constant_(self.fc2.bias, 0.003)\n",
    "                nn.init.constant_(self.fc3.bias, 0.003)\n",
    "                nn.init.constant_(self.fc4.bias, 0.003)\n",
    "                \n",
    "                # Send the neural net to device\n",
    "                self.device = torch.device(device)\n",
    "                self.to(self.device)\n",
    "\n",
    "\n",
    "                \n",
    "        def forward(self, state):\n",
    "\n",
    "                next_state = self.activation(self.fc1(state))\n",
    "                next_state = self.activation(self.fc2(next_state))\n",
    "                next_state = self.activation(self.fc3(next_state))\n",
    "                next_state = self.fc4(next_state)\n",
    "                \n",
    "                return next_state\n",
    "\n",
    "        def guess_xs(self, state, horizon=30):\n",
    "                \"\"\"\n",
    "                Given a starting state, predict the state trajectory for the entire length of the horizon.\n",
    "                The predicted trajectory should be of length horion +1\n",
    "                \"\"\"\n",
    "                xs = []\n",
    "                xs.append(state)\n",
    "\n",
    "                for _ in range(horizon):\n",
    "                        state = self(state)\n",
    "                        xs.append(state)\n",
    "\n",
    "                return torch.stack(xs).cpu().detach().numpy().reshape(horizon+1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PolicyNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griddedData(n_points:int = 1500,\n",
    "                xy_limits:list = [-1.9,1.9],\n",
    "                theta_limits:list = [-np.pi/2, np.pi/2]\n",
    "                ):\n",
    "    size = int(np.sqrt(n_points)) + 1\n",
    "    min_x, max_x = [*xy_limits]\n",
    "    xrange = np.linspace(min_x,max_x,size, endpoint=True)\n",
    "    trange = np.linspace(*theta_limits, size, endpoint=True)\n",
    "    points = np.array([ [x1,x2, x3] for x1 in xrange for x2 in xrange for x3 in trange])\n",
    "    np.round_(points, decimals=6)\n",
    "    np.random.shuffle(points)\n",
    "    points = points[0:n_points, : ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 684.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.1337569, -0.3274067, -0.7395376, ..., -0.       , -0.0415343,\n",
       "         0.       ],\n",
       "       [-1.3155828,  0.1462928, -0.2286472, ...,  0.       , -0.0198724,\n",
       "        -0.       ],\n",
       "       [-0.3536308,  0.0161681,  0.0086907, ...,  0.       ,  0.0163006,\n",
       "        -0.       ],\n",
       "       ...,\n",
       "       [-0.2517442, -0.2730063, -0.4629894, ..., -0.       , -0.063275 ,\n",
       "        -0.       ],\n",
       "       [-0.9774276, -1.8810251,  1.0333852, ..., -0.       , -0.0570211,\n",
       "        -0.       ],\n",
       "       [-0.9613783, -0.4697079,  0.3551636, ..., -0.       , -0.0595095,\n",
       "        -0.       ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = griddedData(500, xy_limits=[-1.9,1.0],theta_limits=[-np.pi/2, np.pi/2])\n",
    "x = []\n",
    "y = []\n",
    "for x0 in tqdm(states):\n",
    "    model = crocoddyl.ActionModelUnicycle()\n",
    "    model.costweights = np.array([1., 1.]).T\n",
    "    problem = crocoddyl.ShootingProblem(x0.T, [model]*30, model)\n",
    "    ddp = crocoddyl.SolverDDP(problem)\n",
    "    ddp.solve([], [] , 1000)\n",
    "    \n",
    "    xs = np.array(ddp.xs[1:]).flatten()\n",
    "    \"\"\"\n",
    "    xs_us = np.hstack((np.array(ddp.xs[1:]), np.array(ddp.us)))\n",
    "    np.round_(xs, 6)\n",
    "    np.round_(xs_us, 6)\n",
    "    assert len(xs) == len(xs_us) + 1\n",
    "    for xs in xs[:-1]:\n",
    "        x.append(xs)\n",
    "        \n",
    "    for xsus in xs_us:\n",
    "        y.append(xsus)\n",
    "    \"\"\"\n",
    "    x.append(x0)\n",
    "    y.append(xs)\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y).squeeze()\n",
    "np.round_(x, 7)\n",
    "np.round_(y, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffle(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = torch.Tensor(x[0:1, :])\n",
    "ytest = y[0:1, :]\n",
    "\n",
    "xtrain = torch.Tensor(x[1:,:])\n",
    "ytrain = torch.Tensor(y[1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(xtrain, ytrain)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = BATCHSIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......  CRITERIA\n",
    "criterion1 = torch.nn.MSELoss(reduction='sum')\n",
    "criterion2 = torch.nn.L1Loss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = torch.optim.Adam(net.parameters(), lr = lr, betas=[0.5, 0.9], weight_decay=DECAY)\n",
    "#opt = torch.optim.ASGD(net.parameters(), lr = lr, weight_decay=DECAY)\n",
    "opt = torch.optim.LBFGS(net.parameters(), history_size=10, max_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 || MAE : 0.035235887239115464 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 1 || MAE : 0.03689823001435039 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 2 || MAE : 0.03359597391448566 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 3 || MAE : 0.5789567779096058 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 4 || MAE : 0.027254674110225727 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 5 || MAE : 0.016909996216323036 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 6 || MAE : 0.3230747741193515 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 7 || MAE : 0.033514698131010864 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 8 || MAE : 0.029112487393715854 || Within 0.01: 0/1 || Within 0.1 : 1/1\n",
      "EPOCH : 9 || MAE : 3.5967880815472317e+37 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 10 || MAE : 5.3873505761343636e+88 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 11 || MAE : 1.3716094232661896e+139 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 12 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 13 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 14 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 15 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 16 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 17 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 18 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 19 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 20 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 21 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 22 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 23 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 24 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 25 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 26 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 27 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 28 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 29 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 30 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 31 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 32 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 33 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 34 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 35 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 36 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 37 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 38 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 39 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 40 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 41 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 42 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 43 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 44 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 45 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 46 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 47 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 48 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 49 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 50 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 51 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 52 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 53 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 54 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 55 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 56 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 57 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 58 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 59 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 60 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 61 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 62 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 63 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 64 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 65 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 66 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 67 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 68 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 69 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 70 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 71 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 72 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 73 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 74 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 75 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 76 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 77 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 78 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 79 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 80 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 81 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 82 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 83 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 84 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 85 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 86 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 87 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 88 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 89 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 90 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 91 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 92 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 93 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 94 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 95 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 96 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 97 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 98 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 99 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 100 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 101 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 102 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 103 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 104 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 105 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 106 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 107 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 108 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 109 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 110 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 111 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 112 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 113 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 114 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 115 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 116 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 117 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 118 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 119 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 120 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 121 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 122 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 123 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 124 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 125 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 126 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 127 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 128 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 129 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 130 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 131 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 132 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 133 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 134 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 135 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 136 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 137 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 138 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 139 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 140 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 141 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 142 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 143 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 144 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 145 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 146 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 147 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 148 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 149 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 150 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 151 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 152 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 153 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 154 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 155 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 156 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 157 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 158 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 159 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 160 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 161 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 162 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 163 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 164 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 165 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 166 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 167 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 168 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 169 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 170 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 171 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 172 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 173 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 174 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 175 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 176 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 177 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 178 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 179 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 180 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 181 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 182 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 183 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 184 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 185 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 186 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 187 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 188 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 189 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 190 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 191 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 192 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 193 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 194 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 195 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n",
      "EPOCH : 196 || MAE : 2.586786890535647e+153 || Within 0.01: 0/1 || Within 0.1 : 0/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fb4ace42f292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fb4ace42f292>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ 0.01*criterion2(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.to(DEVICE)\n",
    "xtest.to(DEVICE)\n",
    "for epoch in range(1000):\n",
    "    for data, target in dataloader:\n",
    "        net.train()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        data        = data.to(DEVICE)\n",
    "        target      = target.to(DEVICE)\n",
    "        #output      = net(data)\n",
    "        \n",
    "        def closure():\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            output = net(data)\n",
    "        \n",
    "            loss        = torch.sqrt(criterion1(output, target)) #+ 0.01*criterion2(output, target)\n",
    "            if loss.requires_grad:\n",
    "                    loss.backward()\n",
    "            return loss\n",
    "            \n",
    "        opt.step(closure)\n",
    "        \n",
    "\n",
    "    \n",
    "    # Validation\n",
    "    acc = 0\n",
    "    acc2 = 0\n",
    "    pred = net(xtest).detach().numpy()\n",
    "    mae = np.mean(np.abs(pred - ytest))\n",
    "    \n",
    "    for i in range(len(xtest)):\n",
    "        xtest[i].resize_(1, 3)\n",
    "        pred = net(xtest[i]).detach().numpy()\n",
    "        \n",
    "        if np.mean(np.abs(pred - ytest[i])) < 0.01:\n",
    "            acc += 1\n",
    "        elif np.mean(np.abs(pred - ytest[i])) < 0.1:\n",
    "            acc2 += 1\n",
    "    print(f\"EPOCH : {epoch} || MAE : {mae} || Within 0.01: {acc}/{len(xtest)} || Within 0.1 : {acc2}/{len(xtest)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess(x):\n",
    "    x = torch.Tensor(x.reshape(1, 3))\n",
    "    xs, us = [], []\n",
    "    xs.append(x)\n",
    "    for _ in range(30):\n",
    "        \n",
    "        policy = net(x).detach().reshape(1, 5)\n",
    "        \n",
    "        xs.append(policy[:,0:3])\n",
    "        us.append(policy[:,3:])\n",
    "        x = policy[:,0:3]\n",
    "    return torch.stack(xs).squeeze().numpy(), torch.stack(us).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5, 1.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x  = np.array([np.random.uniform(-1.5,1.5), np.random.uniform(-1.5,1.5), np.random.uniform(-np.pi/4, np.pi/4)])\n",
    "#np.round_(x, 4)\n",
    "\n",
    "\n",
    "    \n",
    "#_xs, _us = guess(x)\n",
    "_xs = []\n",
    "_xs.append(x)\n",
    "p_xs = net(torch.Tensor(x.reshape(1, 3))).detach().numpy().reshape(30, 3)\n",
    "for _ in p_xs:\n",
    "    _xs.append(_)\n",
    "\n",
    "_xs = np.array(_xs).reshape(31, 3)\n",
    "\n",
    "\n",
    "model               = crocoddyl.ActionModelUnicycle()\n",
    "model.costWeights   = np.array([1.,1.]).T\n",
    "problem             = crocoddyl.ShootingProblem(x.T, [model]*30, model)\n",
    "ddp                 = crocoddyl.SolverDDP(problem)\n",
    "log                 = crocoddyl.CallbackLogger()\n",
    "ddp.setCallbacks([log])\n",
    "ddp.solve([], [], 1000)\n",
    "stops = log.stops[1:]\n",
    "xs = np.array(ddp.xs)\n",
    "\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(1, figsize=(8,6))\n",
    "axs.plot(xs[:,0], xs[:,1], c = 'blue', label= \" Crocoddyl\")\n",
    "\n",
    "axs.plot(_xs[:,0], _xs[:,1], c = 'grey', label= \" Guess\")\n",
    "axs.set_xlim([-1.5,1.5 ])\n",
    "axs.set_ylim([-1.5,1.5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
